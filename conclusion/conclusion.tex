\chapter{Conclusion}

In this project, we have shown that semantic generation of retinal fundus images is viable as a method of data augmentation, and shows great potential in improving the performance downstream tasks.
First, we provided a survey of available datasets and their properties.
To expand our training data, we showed how weak supervision can be used to inflate the training set in low-data regimes.
We then introduced a novel two-step process for the synthesis of realistic retinal fundus images with accompanying semantic labels, conditioned on DR severity.
Finally, we showed that using synthetic data as a basis for mixed-data training or transfer learning can increase the performance of segmentation and classification models on real data.

\section{Limitations}

While it remains true that there is no better substitute for high-quality annotated data, we have shown that synthetic data and its application to medical imaging is a promising avenue of research.
However, it should be noted that this project presents only an early proof-of-concept, and as such exhibits a number of limitations.

Despite the fact that the images used in these experiments were of relatively low resolution when compared to raw images captured by cameras, generation of high-resolution, natural, medical images has already been shown to be feasible \cite{mammogan}.
However, it remains unclear how the same can be reliably done for the generation of sparse semantic labels.
This work suggests that DCGAN-based architectures are ill-suited for this task, and that progressive growing is the key to yielding improved results.

While we were successful in enhancing model performance, there remains much room for improvement in terms of the quality of generated images.
Having seen impressive results on natural looking images, it would be exciting to bring semantic label generation GANs up to parity.
A synthetic data generator can be considered to rely on two major factors, either of which can become a bottleneck: the quality of input data; and the capacity of the model to learn the representation of the data distribution.
There are multiple facets that determine the ``quality'' of training data, the most obvious being simply the volume.
In our case, having less than 2000 training images, and further subdividing this set due to conditioning, makes it difficult to learn a general representation without overfitting.
To test this, we could train the GANs on a large volume of copy-paste generated data, with the goal not necessarily being to generate anatomically correct retinal fundus images, but rather to see if increasing the amount of available data allows a GAN to better represent the images.
Otherwise, if this is not the case then we can identify that the representational power of the generator or discriminator architecture simply is not great enough.

Moreover, the quality of annotations available to us presented an issue.
Many datasets are missing the annotations we needed for these tasks, and other datasets simply have annotations which are too coarse.
Not only is the accuracy and precision in the labels of the training data important, but also the diversity of data.
Changes in imaging conditions, such as field-of-view, focal length, and lighting, can cause differences between the training and production data.
Since generative models aim to create data points which are plausibly sampled from the input distribution, this covariate shift may cause the models trained on synthetic data to not be robust to all field conditions, and therefore produce spurious results.

Finally, there are a number of caveats inherent to the use of synthetic data.
The generative models presented in this work provide no guarantee on the validity or anatomically correctness of generated data.
Hence, the model may be susceptible to producing anomalous results, and a downstream model which incorrectly learns these features will reflect this.
One must also be aware that over-training on synthetic data can cause a model to overfit to unrealistic features in the synthetic data.

\section{Future Work}

In this work, we generated synthetic data that had ``annotations'' for both the segmentation and classification task.
We then evaluated the two tasks separately.
Yet, methods for joint classification and segmentation of the retinal fundus modality exist in the literature \cite{ynet}, so supplying these models with the synthetic samples could be an interesting study, and may improve performance by a greater margin than on each individual task separately.

When conditioning our models, did not incorporate retinal structures such as the vasculature or location of the macula. 
Instead, these details were generated by the SPADE network.
However, these structures potentially contain important anatomical information; for example, the proximity of lesions to the macula may inform the severity of disease.
Incorporating these conditions could further guide and inform the generation of semantic labels.

While thorough, the evaluation for this project was limited to ad-hoc metrics for measuring GAN performance, which may not be entirely appropriate, and so there are a number of improvements that could be made here.
We have discussed how the FID is not ideal for quantifying the quality of retinal fundus images or semantic labels.
It's possible that new metrics must be developed for these modalities -- this could possibly be as simple as training the Inception network used to calculate the FID on retinal fundus images.
Also, we were unable to secure any human experts for this project, meaning we cannot draw any concrete conclusions about the anatomical correctness of generated images.
Further applications not explored here include use in training human experts to better identify retinal lesions, for which we would need highly plausible images.

A large part of this work emphasises the difficulty of training GANs in a stable manner.
While it is generally accepted that GANs lead the state-of-the-art in terms of high-fidelity image generation, other advances in generative models such as VAEs and autoregressive models show potential, bringing into question whether GANs are necessarily the most suitable framework for this use-case.
One considerable advantage that these techniques have is that training is much more stable, and going forward it is well-worth exploring whether equal or greater quality semantic labels can be synthesised by these models.

\section{Ethical Issues} \label{sec:ethics}

In this section, we discuss the potential implications of deploying an automated decision-making system in the context of medicine.

\subsection{Machine Learning in Healthcare}

Machine learning techniques and their application to healthcare have see massive popularity in the past decade, largely thanks to their versatility and ability to achieve groundbreaking results.
The use of artificial intelligence in medicine goes back as far as the 1960s \cite{dendral}, but what sets machine learning apart is its ability to learn directly from large amounts of data, instead of relying on hard-coded rules.

As a result, the usefulness of a machine learning model is bounded by the quality of its training data.
Hence, it is of massive importance that the source data is as free of bias as possible, as prejudice in the training data will translate to prejudice in the decisions that the model makes.
This is not just a hypothetical, but a very real problem that has been demonstrated time and time again.
For instance, in \citeyear{Obermeyer447} \citeauthor{Obermeyer447} \cite{Obermeyer447} found evidence of gross racial bias in a commercial AI system used in the U.S healthcare system.
A similar risk is present in our domain since skin tone affects fundus pigmentation, and the prevalence of ocular diseases has been shown to vary between ethnicities \cite{bourne2011}.
By deliberately sampling an unbalanced subset from the EyePACS dataset, \citeauthor{burlina2020addressing} \cite{burlina2020addressing} was able to show a significant disparity based on skin-tone in the performance of a DR classification model, when trained on unbalanced data.
In our case, data bias is likely since the little data we have is collated from local hospitals, decreasing the chance of a diverse and balanced dataset, and we cannot afford to selectively undersample our data.
The consequence of this is that a synthetic data generator trained on biased data will naturally generate more data reflecting that bias, exacerbating the issue.
\citeauthor{burlina2020addressing} proposed an effective method of debiasing the source data by applying StyleGAN to generate fundus images which are then manipulated in the latent space to exhibit different skin tones.
A similar idea could be interesting to explore as an extension to this project.

\subsection{Data Privacy}

Diabetic retinopathy is not a rare disease, and the precise locations from which the patient data was collected is not given in any of the used datasets.
Applying the ``motivated intruder'' test \cite{ico}, it is clear that individuals will not be directly or indirectly re-identifiable from the retina images.
Since there is no identifying information accompanying the retinal fundus photographs in any of our datasets, and an individual cannot (practically) be identified from a retinal fundus image, we consider our data to be ``truly anonymised'', as defined under Retical 26 of the GDPR \cite{gdpr}.

\subsection{Copyright and Licensing}

To ensure that the contributions of this project are as as freely available as possible, any software will be distributed under a permissive FOSS license.
Proper attribution is desirable, making the (3-clause) BSD license the natural choice.
Since BSD only covers source code, we license other work (images, documentation, etc.) under CC BY 4.0 which is similar to BSD in spirit.
An additional complication is that copyright and licensing only covers works created by humans.
However, since a degree of human creative input did go into creating the synthetic data generator, it's reasonable to put these under the same license.
In terms of using third-party software, we must take care to retain the copyright notices of PyTorch\footnote{\url{https://github.com/pytorch/pytorch/blob/master/LICENSE}} and any other software that uses a similar license. 
This project will not be applied commercially, so we are free to use works licensed under non-commercial licenses such as SPADE\footnote{\url{https://github.com/NVlabs/SPADE/blob/master/LICENSE.md}}.